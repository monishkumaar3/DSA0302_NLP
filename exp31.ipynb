{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKR3HJVukVY3LUCunMLBuB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPheVq4TBsu2","executionInfo":{"status":"ok","timestamp":1700707081789,"user_tz":-330,"elapsed":6740,"user":{"displayName":"Monish Kumaar","userId":"15042714021371901584"}},"outputId":"15fe1a64-448f-48bc-efd2-403f501f5a5f"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Named Entities:\n","Harvard - ORGANIZATION\n","University - GPE\n","Cambridge - GPE\n","Massachusetts - GPE\n","\n","Reference Resolution:\n","ORGANIZATION PLACE, located in PLACE, PLACE, is a prestigious institution.\n"]}],"source":["import nltk\n","from nltk import word_tokenize, pos_tag, ne_chunk\n","\n","# Download NLTK resources\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","# Function to perform named entity recognition (NER) and extract named entities\n","def extract_entities(text):\n","    words = word_tokenize(text)\n","    tagged = pos_tag(words)\n","    entities = ne_chunk(tagged)\n","    named_entities = []\n","    for entity in entities:\n","        if isinstance(entity, nltk.tree.Tree):\n","            named_entity = \" \".join([word for word, tag in entity.leaves()])\n","            named_entities.append((named_entity, entity.label()))\n","    return named_entities\n","\n","# Function to perform reference resolution within a given text\n","def resolve_references(text):\n","    named_entities = extract_entities(text)\n","    resolved_text = text\n","    for entity, entity_type in named_entities:\n","        if entity_type == 'GPE':\n","            resolved_text = resolved_text.replace(entity, 'PLACE')\n","        elif entity_type == 'ORGANIZATION':\n","            resolved_text = resolved_text.replace(entity, 'ORGANIZATION')\n","    return resolved_text\n","\n","# Example text\n","text = \"Harvard University, located in Cambridge, Massachusetts, is a prestigious institution.\"\n","\n","# Extract named entities\n","entities = extract_entities(text)\n","print(\"Named Entities:\")\n","for entity, entity_type in entities:\n","    print(f\"{entity} - {entity_type}\")\n","\n","# Perform reference resolution\n","resolved_text = resolve_references(text)\n","print(\"\\nReference Resolution:\")\n","print(resolved_text)\n"]}]}